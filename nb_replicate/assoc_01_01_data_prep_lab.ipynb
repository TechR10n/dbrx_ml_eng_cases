{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "e8a5e9852cc07074"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "LAB - Load and Explore Data\n",
    "Welcome to the \"Load and Explore Data\" lab! In this session, you will learn essential skills in data loading and exploration using PySpark in a Databricks environment. Gain hands-on experience reading data from Delta tables, managing data permissions, computing summary statistics, and using data profiling tools to unveil insights in your Telco dataset. Let's dive into the world of data exploration!\n",
    "\n",
    "Lab Outline:\n",
    "\n",
    "In this Lab, you will learn how to:\n",
    "\n",
    "Read data from delta table\n",
    "Manage data permissions\n",
    "Show summary statistics\n",
    "Use data profiler to explore data frame\n",
    "Check outliers\n",
    "Check data distributions\n",
    "Read previous versions of the delta table"
   ],
   "id": "acce37fb299220ae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Lab Setup\n",
    "Before starting the Lab, follow these initial steps:\n",
    "\n",
    "Run the provided classroom setup script. This script will establish necessary configuration variables tailored to each user. Execute the following code cell:\n",
    "Other Conventions:\n",
    "\n",
    "Throughout this lab, we'll make use of the object DA, which provides critical variables. Execute the code block below to see various variables that will be used in this notebook:"
   ],
   "id": "74316de465a8aa94"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Task 1: Read Data from Delta Table\n",
    "Use Spark to read data from the Delta table into a DataFrame."
   ],
   "id": "6063f17c1282d18f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T15:45:21.290608Z",
     "start_time": "2024-07-31T15:45:21.287413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO\n",
    "dataset_path = f\"{DA.paths.datasets}/telco/telco-customer-churn-missing.csv\"\n",
    "\n",
    "Read dataset with spark\n",
    "telco_df = <FILL_IN>\n",
    "\n",
    "table_name = \"telco_missing\"\n",
    "table_name_bronze = f\"{table_name}_bronze\"\n",
    "\n",
    "Write it as delta table\n",
    "telco_df.write.<FILL_IN>\n",
    "telco_df.show()"
   ],
   "id": "ee53f6582a0160ad",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2236096865.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[5], line 4\u001B[0;36m\u001B[0m\n\u001B[0;31m    Read dataset with spark\u001B[0m\n\u001B[0m         ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Task 2: Manage Data Permissions\n",
    "Establish controlled access to the Telco Delta table by granting specific permissions for essential actions.\n",
    "\n",
    "Grant permissions for specific actions (e.g., read, write) on the Delta table."
   ],
   "id": "b7e205dfba9c44be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T15:45:21.598784Z",
     "start_time": "2024-07-31T15:45:21.595738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%sql\n",
    "-- TODO\n",
    "Write query to Grant Permission to all the users to access Delta Table\n",
    "<FILL_IN>;"
   ],
   "id": "fe2e267a6a2d78b5",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3326353103.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[6], line 3\u001B[0;36m\u001B[0m\n\u001B[0;31m    Write query to Grant Permission to all the users to access Delta Table\u001B[0m\n\u001B[0m          ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##Task 3: Show Summary Statistics\n",
    "\n",
    "\n",
    "Compute and present key statistical metrics to gain a comprehensive understanding of the Telco dataset.\n",
    "\n",
    "\n",
    "+ Utilize PySpark to compute and display summary statistics for the Telco dataset.\n",
    "\n",
    "+ Include key metrics such as mean, standard deviation, min, max, etc."
   ],
   "id": "48ddb83670069ff9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T15:45:21.896231Z",
     "start_time": "2024-07-31T15:45:21.894057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO\n",
    "Show summary of the Data\n",
    "<FILL_IN> "
   ],
   "id": "2b8405fc6fe16fe3",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2973398001.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[7], line 2\u001B[0;36m\u001B[0m\n\u001B[0;31m    Show summary of the Data\u001B[0m\n\u001B[0m         ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Task 4: Use Data Profiler to Explore DataFrame\n",
    "Use the Data Profiler and Visualization Editor tools.\n",
    "\n",
    "Use the Data Profiler to explore the structure, data types, and basic statistics of the DataFrame.\n",
    "- Task 4.1.1: Identify columns with missing values and analyze the percentage of missing data for each column.\n",
    "- Task 4.1.2: Review the data types of each column to ensure they match expectations. Identify any columns that might need type conversion.\n",
    "- Use Visualization Editor to Check Outliers and Data Distributions:\n",
    "- Task 4.2.1: Create a bar chart to visualize the distribution of churned and non-churned customers.\n",
    "- Task 4.2.2: Generate a pie chart to visualize the distribution of different contract types.\n",
    "- Task 4.2.3: Create a scatter plot to explore the relationship between monthly charges and total charges.\n",
    "- Task 4.2.4: Visualize the count of customers for each payment method using a bar chart.\n",
    "- Task 4.2.5: Compare monthly charges for different contract types using a box plot."
   ],
   "id": "7f41ef882f21c26a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T15:45:22.190398Z",
     "start_time": "2024-07-31T15:45:22.188801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the data and Explore the Data Profiler and Visualization Editor\n",
    "#<FILL_IN>"
   ],
   "id": "b39001b7f1022c0a",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T15:45:22.405360Z",
     "start_time": "2024-07-31T15:45:22.374006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the data and Explore the Data Profiler and Visualization Editor\n",
    "display(telco_df)"
   ],
   "id": "f0cf25f4aeafa4b6",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'telco_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Display the data and Explore the Data Profiler and Visualization Editor\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m display(\u001B[43mtelco_df\u001B[49m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'telco_df' is not defined"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Task 5: Drop the Column\n",
    "Remove a specific column, enhancing data cleanliness and focus.\n",
    "\n",
    "Identify the column that needs to be dropped. For example, let's say we want to drop the 'SeniorCitizen' column.\n",
    "\n",
    "Use the appropriate command or method to drop the identified column from the Telco dataset.\n",
    "\n",
    "Verify that the column has been successfully dropped by displaying the updated dataset."
   ],
   "id": "92124a814c6757b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T15:45:22.644387Z",
     "start_time": "2024-07-31T15:45:22.642127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO\n",
    "Drop SeniorCitizen Column \n",
    "telco_dropped_df = <FILL_IN>\n",
    "\n",
    "Overwrite the Delta table\n",
    "telco_dropped_df.write.mode(\"overwrite\")<FILL_IN>"
   ],
   "id": "706166857b9091b4",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1580584074.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[10], line 2\u001B[0;36m\u001B[0m\n\u001B[0;31m    Drop SeniorCitizen Column\u001B[0m\n\u001B[0m         ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Task 6: Time-Travel to First\n",
    "Revert the Telco dataset back to its initial state, exploring the characteristics of the first version.\n",
    "\n",
    "Utilize time-travel capabilities to revert the dataset to its initial version.\n",
    "\n",
    "Display and analyze the first version of the Telco dataset to understand its original structure and content."
   ],
   "id": "c3ac90caf7e61687"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T15:45:22.946244Z",
     "start_time": "2024-07-31T15:45:22.943984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO\n",
    "Extract timestamp of first version (can also be set manually)\n",
    "timestamp_v0 = spark.sql(<FILL_IN>)\n",
    "(spark\n",
    "        .read\n",
    "        .option(<FILL_IN>)\n",
    "        .table(<FILL_IN>)\n",
    "        .printSchema()\n",
    ")"
   ],
   "id": "4c460a80baecdef0",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1745600628.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[11], line 2\u001B[0;36m\u001B[0m\n\u001B[0;31m    Extract timestamp of first version (can also be set manually)\u001B[0m\n\u001B[0m            ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Task 7: Read previous versions of the delta table\n",
    "Demonstrate the ability to read data from a specific version of the Delta table.\n",
    "\n",
    "Replace the timestamp in the code with the actual version or timestamp of interest."
   ],
   "id": "863b76cbc50267f1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Conclusion\n",
    "In this lab, you demonstrated how to explore and manipulate the dataset using Databricks, focusing on data exploration, management, and time-travel capabilities."
   ],
   "id": "b5d500ca85b11c6a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-31T15:45:23.429194Z",
     "start_time": "2024-07-31T15:45:23.426428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%sql\n",
    "-- TODO\n",
    "Show table versions\n",
    "<FILL_IN>"
   ],
   "id": "602c5511129cf4e6",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4224220345.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[12], line 3\u001B[0;36m\u001B[0m\n\u001B[0;31m    Show table versions\u001B[0m\n\u001B[0m         ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ca7ce188f25ab250"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

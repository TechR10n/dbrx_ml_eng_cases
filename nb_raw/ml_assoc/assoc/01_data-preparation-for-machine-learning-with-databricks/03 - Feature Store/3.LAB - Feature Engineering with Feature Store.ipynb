{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd547a2a-1c4c-49c6-83b0-851048def816",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5fc1e050-acfc-4a8c-bf23-f5a74915d007",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "# LAB - Feature Engineering with Feature Store\n",
    "\n",
    "Welcome to the \"Feature Engineering with Feature Store\" In this lesson, you will learn how to load and prepare a dataset for feature selection, explore and manipulate a feature table through Databricks UI, perform feature selection on specific columns, create a new feature table, access feature table details using both UI and API, merge two feature tables based on a common identifier, and efficiently delete unnecessary feature tables. Get ready to enhance your feature engineering skillsâ€”let's dive in!\n",
    "\n",
    "**Lab Outline:**\n",
    "\n",
    "In this Lab, you will learn how to:\n",
    "\n",
    "1. Load and Prepare Dataset for Feature Selection\n",
    "2. Explore Feature Table through UI\n",
    "3. Access Feature Table Information\n",
    "4. Create Feature Table from Existing UC Table\n",
    "5. Enhance Feature Table with New Features\n",
    "6. Efficient Feature Table Deletion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3eadbfe2-18db-4224-b33e-a674442370a1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Requirements\n",
    "\n",
    "Please review the following requirements before starting the lesson:\n",
    "\n",
    "* To run this notebook, you need to use one of the following Databricks runtime(s): **13.3.x-cpu-ml-scala2.12**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38ae9594-ae9e-4b61-afb5-06bb63d4ed98",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Classroom Setup\n",
    "\n",
    "Before starting the demo, run the provided classroom setup script. This script will define configuration variables necessary for the demo. Execute the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b0445b64-8b6c-4589-80eb-7007b9569265",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../Includes/Classroom-Setup-03L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf7307f6-d9ec-40b9-9466-f2a0431f234c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Other Conventions:**\n",
    "\n",
    "Throughout this demo, we'll refer to the object `DA`. This object, provided by Databricks Academy, contains variables such as your username, catalog name, schema name, working directory, and dataset locations. Run the code block below to view these details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2609c927-11ac-400d-a6d1-5f2b3fb4462c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Username:          {DA.username}\")\n",
    "print(f\"Catalog Name:      {DA.catalog_name}\")\n",
    "print(f\"Schema Name:       {DA.schema_name}\")\n",
    "print(f\"Working Directory: {DA.paths.working_dir}\")\n",
    "print(f\"User DB Location:  {DA.paths.datasets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "02909039-dfea-450f-b42b-76179f8f2bba",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Data Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "20151091-ab67-45ae-8b75-b260f0ac4a26",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataset_path = f\"{DA.paths.datasets}/cdc-diabetes/diabetes_binary_5050split_BRFSS2015.csv\"\n",
    "silver_df = spark.read.csv(dataset_path, header=\"true\", inferSchema=\"true\", multiLine=\"true\", escape='\"')\n",
    "display(silver_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98a174d5-dc19-4fc5-9ccf-2428979cbd11",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Task1: Feature Selection\n",
    "\n",
    "The dataset is loaded and ready. We are assuming that most of the data cleaning and feature computation is already done and data is saved to \"silver\" table.\n",
    "\n",
    "Select these features from the dataset; **\"HighBP\", \"HighChol\", \"BMI\", \"Stroke\", \"PhysActivity\", \"GenHlth\", \"Sex\", \"Age\", \"Education\", \"Income\". **\n",
    "\n",
    "Create a `UID` column to be used as primary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b344f6c-277e-4e9b-abee-c2a305738ff3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "# select features we are interested in\n",
    "silver_df = <FILL_IN>\n",
    "\n",
    "# drop the target column\n",
    "silver_df = <FILL_IN>\n",
    "\n",
    "# create an UID column to be used as primary key\n",
    "silver_df = <FILL_IN>\n",
    "\n",
    "display(silver_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77812a24-5fce-45d1-8dd1-3e1c65a85eb2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Task 2: Create a Feature Table\n",
    "\n",
    "\n",
    "Create a feature table from the `silver_df` dataset. Define description and tags as you wish.\n",
    "\n",
    "New feature table name must be **`diabetes_features`**.\n",
    "\n",
    "**Note:** Don't define partition column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d13592e8-9e78-4608-988e-b6f486948b5b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "\n",
    "fe = <FILL_IN>\n",
    "\n",
    "diabetes_table_name = <FILL_IN>\n",
    "\n",
    "fe.create_table(<FILL_IN>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c08518c4-97f5-4f0d-9eae-f49b4527e8d2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Task 3: Explore Feature Table with the UI\n",
    "\n",
    "Now that the feature table is created, visit **Features** page from the left panel and review following information;\n",
    "\n",
    "* Check table columns, identify **primary key** and **partition** columns.\n",
    "\n",
    "* View **sample data**.\n",
    "\n",
    "* View table **details**. \n",
    "\n",
    "* View **history**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9803d3c9-540f-4157-8d7f-b3cda16c3aec",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Task 4: Retrieve Feature Table Details\n",
    "\n",
    "Another way of accessing the feature table is using the API. Let's **list `features` and `primary_keys`** of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23e876ec-ee1b-4275-ac65-75e75cc0b9ec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "ft = fe.<FILL_IN>\n",
    "print(f\"Features: {ft.<FILL_IN>}\")\n",
    "print(f\"Primary Keys: {ft.<FILL_IN>}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bca764ec-a4b1-4890-a650-f88771a4c13f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Task 5: Create a Feature Table from an Existing UC Table\n",
    "\n",
    "There is a table already created for you which includes diet related features. The table name is **`diet_features`**. Create a feature table for this existing table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5861ef41-5b7b-45f0-9881-2cfaad1aabe0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(\"SELECT * FROM diet_features\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "700ebd79-c3f7-40d4-aee8-cc1425dd2abb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- TODO\n",
    "set UID column to not null\n",
    "<FILL_IN>\n",
    "\n",
    "set UID column as primary key contraint\n",
    "<FILL_IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13c49ff5-d365-4d6a-be17-67940cae062a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Task 6: Add New Features to Existing Table\n",
    "\n",
    "Let's collect diet features and merge them to the existing `diabetes_features` table. As both tables has `UID` as unique identifier, we will merge them based on this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a66aacbb-f775-42f4-b2cb-df4e9d465354",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "diet_features = spark.sql(\"SELECT * FROM diet_features\")\n",
    "\n",
    "Update diabetes feature table by adding diet features table\n",
    "fe.<FILL_IN>\n",
    "\n",
    "Read and display the merged feature table\n",
    "display(fe.<FILL_IN>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "04bad541-2e12-4159-9b64-badf3ae69534",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Task 7: Delete a Feature Table\n",
    "\n",
    "We merged both feature tables and we no longer need the `diet_features` table. Thus, let's delete this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41dcbeaa-fc78-4edc-997b-266b916042e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "diet_table_name = f\"{DA.catalog_name}.{DA.schema_name}.diet_features\"\n",
    "\n",
    "drop the table\n",
    "fe.<FILL_IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5af69ac-7ba9-41a0-ae3e-66a49c7ba4f0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Clean up Classroom\n",
    "\n",
    "Run the following cell to remove lessons-specific assets created during this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ab0f184a-6664-4066-9366-02c96f9d6c68",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DA.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "962f6d3c-7124-45a5-94ed-21b6687576f9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "In this lab, you demonstrated the use of Databricks Feature Store to perform feature engineering tasks. You executed the loading, preparation, and selection of features from a dataset, created a feature table, explored and accessed table details through both the UI and API, merged tables, and efficiently removed unnecessary ones. \n",
    "\n",
    "This hands-on experience enhanced your feature engineering skills on the Databricks platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68c530aa-9b5a-4e94-b407-8149fc11013d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "&copy; 2024 Databricks, Inc. All rights reserved.<br/>\n",
    "Apache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n",
    "<br/>\n",
    "<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "3.LAB - Feature Engineering with Feature Store",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

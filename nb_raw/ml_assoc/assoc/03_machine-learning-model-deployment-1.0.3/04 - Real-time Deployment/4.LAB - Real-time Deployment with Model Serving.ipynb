{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e4520589-7585-4809-a7b9-272c54ec10e6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f755c31-f61c-4631-8598-8a01475600ee",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "# LAB - Real-time Deployment with Model Serving\n",
    "\n",
    "In this lab, you will deploy ML models with Databricks Model Serving **with and without a feature table**. This lab includes **two** sections.\n",
    "\n",
    "In the first section, you will deploy a model for real-time inference with Model Serving's **UI**. This section will demonstrate the most basic and simple way of deploying models with Model Serving. \n",
    "\n",
    "For the second section, you will deploy a model with with an **online feature table using the API**. \n",
    "\n",
    "For both sections, data preparation, model fitting and model registration are already done for you! You just need to focus on the deployment part.\n",
    "\n",
    "**Lab Outline:**\n",
    "\n",
    "* Simple real-time deployment\n",
    "  \n",
    "  - **Task 1:** Serve the model using the UI\n",
    "  \n",
    "  - **Task 2:** Query the endpoint\n",
    "\n",
    "* Real-time deployment with Online Features\n",
    "\n",
    "  - **Task 3**: Create an online feature table\n",
    "\n",
    "  - **Task 4:** Deploy a model with the online feature table\n",
    "\n",
    "  - **Task 5:** Query the endpoint \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ccaf260d-eb88-48a6-8da8-be4cd4103ed9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Requirements\n",
    "\n",
    "Please review the following requirements before starting the lesson:\n",
    "\n",
    "* To run this notebook, you need to use one of the following Databricks runtime(s): **13.3.x-cpu-ml-scala2.12**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6606390a-022a-45eb-86ad-c31788d0bc80",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Classroom Setup\n",
    "\n",
    "Before starting the demo, run the provided classroom setup scripts. \n",
    "\n",
    "**ðŸ“Œ Note:** In this lab you will using the Databricks SDK to create Model Serving endpoint. Therefore, you will need to run the next code block to **install `databricks-sdk`**. \n",
    "\n",
    "Before starting the demo, run the provided classroom setup script. This script will define configuration variables necessary for the demo. Execute the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "942a1dd2-4d02-40ed-b1d4-2d3b29f5dae7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-sdk --upgrade\n",
    "\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b4228d4-ec1f-48ce-9772-23403f2d514f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1923c317-9593-48f2-be4f-3dac5a2637a9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../Includes/Classroom-Setup-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "79889cdf-b817-45a8-aef2-02b59fba1b30",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Other Conventions:**\n",
    "\n",
    "Throughout this demo, we'll refer to the object `DA`. This object, provided by Databricks Academy, contains variables such as your username, catalog name, schema name, working directory, and dataset locations. Run the code block below to view these details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44da478b-8113-4621-96db-6e26bd4d1bdf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Username:          {DA.username}\")\n",
    "print(f\"Catalog Name:      {DA.catalog_name}\")\n",
    "print(f\"Schema Name:       {DA.schema_name}\")\n",
    "print(f\"Working Directory: {DA.paths.working_dir}\")\n",
    "print(f\"Dataset Location:  {DA.paths.datasets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e094fb9a-9745-4cbc-8ef5-cc5f0d425712",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Data and Model Preparation\n",
    "\n",
    "Before you start the deployment process, you will need to fit and register a model. In this section, you will load dataset, fit a model and register it with UC.\n",
    "\n",
    "**Note:** All necessary code is provided, which means you don't need to complete anything in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a9f3fe3-ef6e-4c8c-bd80-bc052999c3e4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df9a64fb-a0a1-4f59-9e04-6b1f34d5b5bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, monotonically_increasing_id\n",
    "\n",
    "# dataset path\n",
    "dataset_path = f\"{DA.paths.datasets}/cdc-diabetes/diabetes_binary_5050split_BRFSS2015.csv\"\n",
    "\n",
    "df = spark.read.csv(dataset_path, inferSchema=True, header=True, multiLine=True, escape='\"')\\\n",
    "    .na.drop(how='any')\n",
    "\n",
    "df = df.withColumn(\"uniqueID\", monotonically_increasing_id())   # Add unique_id column\n",
    "\n",
    "# Dataset specs\n",
    "primary_key = \"uniqueID\"\n",
    "response = \"Diabetes_binary\"\n",
    "\n",
    "# Separate features and ground-truth\n",
    "features_df = df.drop(response)\n",
    "response_df = df.select(primary_key, response)\n",
    "\n",
    "# Convert data to pandas dataframes\n",
    "X_train_pdf = features_df.drop(primary_key).toPandas()\n",
    "Y_train_pdf = response_df.drop(primary_key).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "870708d3-2db0-4b70-8120-3bff60353ae6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Setup Model Registery with UC\n",
    "\n",
    "Before we start model deployment, we need to fit and register a model. In this demo, **we will log models to Unity Catalog**, which means first we need to setup the **MLflow Model Registry URI**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "06839e75-4d58-4eaf-b98e-6f3a46b5c053",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# Point to UC model registry\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "client = mlflow.MlflowClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ae3c457-3a33-4a5e-a231-dda6db954536",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Helper Class for Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0bc94f9d-9ccf-4943-8b2b-6db2d72fe6fd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "from mlflow.types.utils import _infer_schema\n",
    "from mlflow.models import infer_signature\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "\n",
    "model_name = f\"{DA.catalog_name}.{DA.schema_name}.ml_diabetes_model\" # Use 3-level namespace\n",
    "\n",
    "def get_latest_model_version(model_name):\n",
    "    \"\"\"Helper function to get latest model version\"\"\"\n",
    "    model_version_infos = client.search_model_versions(\"name = '%s'\" % model_name)\n",
    "    return max([model_version_info.version for model_version_info in model_version_infos])\n",
    "\n",
    "def fit_and_register_model(X, Y, model_name_=model_name, random_state_=42, model_alias=None, log_with_fs=False, training_set_spec_=None):\n",
    "    \"\"\"Helper function to train and register a decision tree model\"\"\"\n",
    "\n",
    "    clf = DecisionTreeClassifier(random_state=random_state_)\n",
    "    with mlflow.start_run(run_name=\"LAB4-Real-Time-Deployment\") as mlflow_run:\n",
    "\n",
    "        # Enable automatic logging of input samples, metrics, parameters, and models\n",
    "        mlflow.sklearn.autolog(\n",
    "            log_input_examples=True,\n",
    "            log_models=False,\n",
    "            log_post_training_metrics=True,\n",
    "            silent=True)\n",
    "        \n",
    "        clf.fit(X, Y)\n",
    "\n",
    "        # Log model and push to registry\n",
    "        if log_with_fs:\n",
    "            # Infer output schema\n",
    "            try:\n",
    "                output_schema = _infer_schema(Y)\n",
    "            except Exception as e:\n",
    "                warnings.warn(f\"Could not infer model output schema: {e}\")\n",
    "                output_schema = None\n",
    "            \n",
    "            # Log using feature engineering client and push to registry\n",
    "            fe = FeatureEngineeringClient()\n",
    "            fe.log_model(\n",
    "                model = clf,\n",
    "                artifact_path = \"decision_tree\",\n",
    "                flavor = mlflow.sklearn,\n",
    "                training_set = training_set_spec_,\n",
    "                output_schema = output_schema,\n",
    "                registered_model_name = model_name_\n",
    "            )\n",
    "        \n",
    "        else:\n",
    "            signature = infer_signature(X, Y)\n",
    "            example = X[:3]\n",
    "            mlflow.sklearn.log_model(\n",
    "                clf,\n",
    "                artifact_path = \"decision_tree\",\n",
    "                signature = signature,\n",
    "                input_example = example,\n",
    "                registered_model_name = model_name_\n",
    "            )\n",
    "\n",
    "        # Set model alias\n",
    "        if model_alias:\n",
    "            time.sleep(10) # Wait 10secs for model version to be created\n",
    "            client.set_registered_model_alias(model_name_, model_alias, get_latest_model_version(model_name_))\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f152842-3cc7-46b1-ae68-c3cf43f6e337",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Fit and Register the Model\n",
    "\n",
    "Before we start model deployment process, we will **fit and register a model**. The model's alias will be set to `Production` and it will be served with Databricks Model Serving in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ea55d1e-4e07-4795-b261-b10adb8e199c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = fit_and_register_model(X_train_pdf, Y_train_pdf, model_name, 42, \"Production\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bdbefbf4-3067-436a-bd1c-d1aa63c9db78",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Simple Real-time Model Deployment\n",
    "\n",
    "Now that the model is registered and ready for deployment, the next step is to create a serving endpoint with Model Serving and serve the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c80f029-924f-4684-a255-f860be078321",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Task 1: Serve the Model Using the UI\n",
    "\n",
    "Serve the **\"Production\"** model that we registered in the previous section using the following endpoint configuration.\n",
    "\n",
    "**Configuration:**\n",
    "\n",
    "* Name: `la4-1-diabetes-model`\n",
    "\n",
    "* Compute Size: `small` (CPU)\n",
    "\n",
    "* Autoscaling: `Scale to zero`\n",
    "\n",
    "* Tags: Define tags that might be meaningful for this deployment\n",
    "\n",
    "\n",
    "**ðŸ’¡ Note:** Endpoint creation will take sometime. Therefore, you can work on the next section  while the endpoint is created for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "258852d4-4bf6-4bf8-a6ad-d6d649ee4afb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Task 2: Query the Endpoint \n",
    "\n",
    "Test the model deployment using the **Query endpoint** feature in browsers. Use the provided **Example request** payload to use the model for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0c97459-887e-4b16-84f6-a7854ae600c2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Real-time Model Deployment with Online Store\n",
    "\n",
    "In this section you will deploy a model with a feature table using Databricks' Online Tables. Also, instead of using the UI for creating and configuring the serving endpoint, this time you will need to use the API. \n",
    "\n",
    "Note that feature table creation code is already provided for you. You just need to focus on creating Online Tables and deploying the model along with the online feature table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "76745653-a599-42c8-8f59-2cf1e08735a5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create Feature Table\n",
    "\n",
    "Let's create a feature table to store the features that will be use for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d28daa9a-73cd-4763-968c-08395abe1750",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.feature_engineering import FeatureLookup, FeatureEngineeringClient\n",
    "\n",
    "feature_table_name = f\"{DA.catalog_name}.{DA.schema_name}.diabetes_features\"\n",
    "fe = FeatureEngineeringClient()\n",
    "\n",
    "# Create feature table\n",
    "fe.create_table(\n",
    "    name=feature_table_name,\n",
    "    df=features_df,\n",
    "    primary_keys=[primary_key],\n",
    "    description=\"Diabetes features table\"\n",
    ")\n",
    "\n",
    "# Create training set based on feature lookup\n",
    "fl_handle = FeatureLookup(\n",
    "    table_name=feature_table_name,\n",
    "    lookup_key=[primary_key]\n",
    ")\n",
    "\n",
    "training_set_spec = fe.create_training_set(\n",
    "    df=response_df,\n",
    "    label=response,\n",
    "    feature_lookups=[fl_handle],\n",
    "    exclude_columns=[primary_key]\n",
    ")\n",
    "\n",
    "# Load training dataframe based on defined feature-lookup specification\n",
    "training_df = training_set_spec.load_df()\n",
    "\n",
    "# Convert data to pandas dataframes\n",
    "X_train_pdf2 = training_df.drop(primary_key, response).toPandas()\n",
    "Y_train_pdf2 = training_df.select(response).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c88de86-3fbf-46ed-9e10-0dd55137368f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Fit a Model with Feature Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1721fc8-1f10-4440-8cc7-4e91d4f45971",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_name_2 = f\"{DA.catalog_name}.{DA.schema_name}.ml_diabetes_model_fe\"\n",
    "model_fe = fit_and_register_model(X_train_pdf2, Y_train_pdf2, model_name_2, 20, log_with_fs=True, training_set_spec_=training_set_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93a259f1-e98f-4d11-abb0-0e2807981481",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Task 3: Create a Databricks Online Table\n",
    "\n",
    "As we created the model and registered it with feature store, we will need to integrate the feature table for inference. For real-time inference, Model Serving will need to access features in real-time. \n",
    "\n",
    "**Create an online feature table using following configurations:**\n",
    "\n",
    "* Table name: `diabetes_online_feature_table`\n",
    "\n",
    "* Sync mode: `Snapshot`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6311e9b-02b9-434d-b3e3-edbfac42ac9c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Task 4: Deploy the Model with Online Store\n",
    "\n",
    "Create an endpoint with following configuration;\n",
    "\n",
    "* Autoscaling: `Scale-to-zero`\n",
    "\n",
    "* Compute size: `Small`\n",
    "\n",
    "**ðŸ’¡ Note:** Endpoint creation will take sometime. Be patient while the endpoint is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30b34395-4b6b-416a-a86f-35514a6e8736",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.serving import EndpointCoreConfigInput, EndpointTag\n",
    "\n",
    "# Create/Update endpoint and deploy model+version\n",
    "w = WorkspaceClient()\n",
    "\n",
    "# Get model version that will be served\n",
    "fs_model_version = get_latest_model_version(model_name_2)\n",
    "\n",
    "# Endpoint configuration\n",
    "fs_endpoint_config_dict = {\n",
    "   \"served_models\": [\n",
    "       {\n",
    "          <FILL_IN>\n",
    "       }\n",
    "   ]\n",
    "}\n",
    "fs_endpoint_config = <FILL_IN>\n",
    "\n",
    "\n",
    "fs_endpoint_name = f\"ML_AS_03_Lab4_FS_{DA.unique_name('_')}\"\n",
    "try:\n",
    "   w.<FILL_IN>(\n",
    "     name=<FILL_IN>,\n",
    "     config=<FILL_IN>,\n",
    "     tags=[EndpointTag.from_dict({\"key\": \"db_academy\", \"value\": \"lab4_serve_fs_model\"})]\n",
    "   )\n",
    "  \n",
    " print(f\"Creating endpoint {fs_endpoint_name} with models {model_name} versions {fs_model_version}\")\n",
    "\n",
    "except Exception as e:\n",
    "   if \"already exists\" in e.args[0]:\n",
    "     print(f\"Endpoint with name {fs_endpoint_name} already exists\")\n",
    "  else:\n",
    "     raise(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c03c78ac-6d83-4190-8c7e-1a84c582df77",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Task 5: Query the Endpoint\n",
    "\n",
    "After the endpoint is created, it is time to test it. Use the following hard-coded test-sample to query the endpoint using the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0eb78fbf-2fcf-44cb-a236-68f2bba86174",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Hard-coded test-sample. Feel free to change the ids\n",
    "dataframe_records_lookups_only = [\n",
    "    {\"uniqueID\": \"123\"},\n",
    "    {\"uniqueID\": \"45678\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4db56fae-45ae-42c9-9945-ae7bb374410f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Query the serving endpoint with test-sample\n",
    "query_response = w.serving_endpoints.<FILL_IN>\n",
    "print(f\"FS Inference results: {query_response.<FILL_IN>}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc898fbd-94a7-4743-81de-428c0f29b832",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Clean up Classroom\n",
    "\n",
    "Run the following cell to remove lessons-specific assets created during this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0af70eef-ed0a-4747-9ed0-1057a70fc968",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DA.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4c13489-83c5-4eb3-b43f-3ddd9170828b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "Great job for completing this lab! In this lab, you completed two main tasks: deploying a model with Model Serving using both with and without feature store tables. In the first section of the lab, the main task was to deploy a model simply using the UI. The second section focused on registering a model with a feature table, creating an online feature table from an existing table, and serving a model with an online feature store. Additionally, for each of these methods, there was an endpoint query task to test the endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44ba9cff-df74-4c7a-a82e-8cad2144d37b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "&copy; 2024 Databricks, Inc. All rights reserved.<br/>\n",
    "Apache, Apache Spark, Spark and the Spark logo are trademarks of the \n",
    "<a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n",
    "<br/><a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | \n",
    "<a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | \n",
    "<a href=\"https://help.databricks.com/\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "4.LAB - Real-time Deployment with Model Serving",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
